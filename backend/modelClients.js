// backend/modelClients.js
import dotenv from "dotenv";
dotenv.config();

const OPENAI_RESPONSES_URL = "https://api.openai.com/v1/responses";
const DEEPSEEK_BASE =
  process.env.DEEPSEEK_BASE_URL || "https://api.deepseek.com/chat/completions";
const GEMINI_BASE = "https://generativelanguage.googleapis.com/v1beta";

/* ================= å·¥å…·å‡½æ•° ================= */

/** ä» OpenAI Responses API ä¸­æå–æ–‡æœ¬ */
function extractTextFromResponse(json) {
  const outputs = json.output || [];
  let text = "";

  for (const item of outputs) {
    if (item.type === "message") {
      const part = item.content?.find(p => p.type === "output_text");
      if (part?.text) text += part.text;
    }
  }

  return text.trim();
}

/* ============= ç”»å¸ƒ ============= */

function extractTextAndCanvas(json) {
  const result = {
    text: "",
    canvas: null
  };

  const outputs = json.output || [];

  for (const item of outputs) {
    // æ™®é€šæ–‡æœ¬
    if (item.type === "message") {
      const part = item.content?.find(p => p.type === "output_text");
      if (part?.text) result.text += part.text;
    }

    // ğŸ¨ Canvas
    if (item.type === "canvas") {
      result.canvas = {
        title: item.title || "æœªå‘½åç”»å¸ƒ",
        content: item.content || ""
      };
    }
  }

  return result;
}

/** é€šç”¨è¶…æ—¶ fetchï¼ˆç§»åŠ¨ç«¯/å¼±ç½‘å¿…å¤‡ï¼‰ */
function sleep(ms) {
  return new Promise(r => setTimeout(r, ms));
}

function isRetryableStatus(status) {
  return status === 429 || (status >= 500 && status <= 599);
}

function isRetryableError(err) {
  const msg = String(err?.message || err);
  return (
    msg.includes("AbortError") ||
    msg.includes("ETIMEDOUT") ||
    msg.includes("ECONNRESET") ||
    msg.includes("ENOTFOUND") ||
    msg.includes("EAI_AGAIN")
  );
}

/** è¶…æ—¶ + é‡è¯•ï¼ˆæŒ‡æ•°é€€é¿ï¼‰ */
async function fetchWithRetry(url, options = {}, cfg = {}) {
  const {
    timeoutMs = 60000,
    retries = 2,
    baseDelayMs = 600,
    maxDelayMs = 2500
  } = cfg;

  let lastErr;

  for (let attempt = 0; attempt <= retries; attempt++) {
    const controller = new AbortController();
    const id = setTimeout(() => controller.abort(), timeoutMs);

    try {
      const res = await fetch(url, { ...options, signal: controller.signal });

      // 429/5xxï¼šå¯é‡è¯•
      if (isRetryableStatus(res.status) && attempt < retries) {
        const delay = Math.min(maxDelayMs, baseDelayMs * Math.pow(2, attempt));
        await sleep(delay);
        continue;
      }

      return res;
    } catch (err) {
      lastErr = err;
      if (attempt < retries && isRetryableError(err)) {
        const delay = Math.min(maxDelayMs, baseDelayMs * Math.pow(2, attempt));
        await sleep(delay);
        continue;
      }
      throw err;
    } finally {
      clearTimeout(id);
    }
  }

  throw lastErr;
}

/* ================= æ–°å¢ä¸€ä¸ªèƒ½åŠ›é©±åŠ¨å…¥å£ ================= */

export async function callModelWithConfig(config, messages, options = {}) {
  const { provider, model, capabilities } = config;

  const depthMode = !!(options.depthMode && capabilities?.reasoning === true);
  const webSearch = !!(options.webSearch && capabilities?.webSearch === true);
  const outputTarget = options.outputTarget || "chat"; // "chat" | "canvas"
  const canvasTitle = options.canvasTitle || "ç”»å¸ƒ";

  try {
    let raw;

    if (provider === "openai") {
      raw = await callOpenAI(model, messages, {
        depthMode,
        webSearch,
        outputTarget
      });
    } else if (provider === "deepseek") {
      raw = await callDeepSeek(model, messages, depthMode);
    } else if (provider === "gemini") {
      raw = await callGemini(model, messages, depthMode);
    } else {
      throw new Error("æœªçŸ¥ provider: " + provider);
    }

    // ç»Ÿä¸€å½¢æ€ï¼šå½“ outputTarget=canvas æ—¶ï¼Œä¿è¯è¿”å› { text, canvas }
    if (outputTarget === "canvas") {
      if (typeof raw === "string") {
        return { text: "", canvas: { title: canvasTitle, content: raw } };
      }
      if (raw && typeof raw === "object") {
        if (raw.canvas && (raw.canvas.content || raw.canvas.title)) return raw;
        const t = raw.text || "";
        return { text: "", canvas: { title: canvasTitle, content: t } };
      }
      return { text: "", canvas: { title: canvasTitle, content: "" } };
    }

    return raw;
  } catch (err) {
    console.error(`[ModelError] ${provider}/${model}`, err);
    const msg = "âš ï¸ å½“å‰æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•æˆ–åˆ‡æ¢æ¨¡å‹ã€‚";
    if (outputTarget === "canvas") {
      return { text: "", canvas: { title: canvasTitle, content: msg } };
    }
    return msg;
  }
}

/* ================= OpenAIï¼ˆGPT-5 / Visionï¼‰ ================= */

async function callOpenAI(model, messages, options = {}) {
  const { depthMode, webSearch, outputTarget } = options;
  
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) throw new Error("ç¼ºå°‘ OPENAI_API_KEY");

const CANVAS_SYSTEM_HINT = `
å½“ä½ è¦è¾“å‡ºä»¥ä¸‹ç±»å‹å†…å®¹æ—¶ï¼Œè¯·ä½¿ç”¨ã€Canvas ç”»å¸ƒã€‘è€Œä¸æ˜¯æ™®é€šå›å¤ï¼š
- ä»£ç ï¼ˆä»»ä½•è¯­è¨€ï¼‰
- æ•™ç¨‹ / æ–‡æ¡£ / æ–¹æ¡ˆè¯´æ˜
- è¡¨æ ¼ / æ¸…å• / é•¿æ–‡æœ¬ï¼ˆ>30 è¡Œï¼‰
- ç”¨æˆ·æ˜ç¡®è¦æ±‚â€œæ•´ç†â€â€œç”Ÿæˆæ–‡ä»¶â€â€œå†™æˆæ–‡æ¡£â€çš„å†…å®¹

Canvas è¦æ±‚ï¼š
- æœ‰æ˜ç¡®æ ‡é¢˜
- å†…å®¹ç»“æ„æ¸…æ™°
- åªæ”¾æœ€ç»ˆç»“æœï¼Œä¸è¦èŠå¤©è¯­æ°”
- å†…å®¹å¿…é¡»å®Œæ•´ã€å¯å¤åˆ¶ã€å¯ä¿å­˜ä¸ºæ–‡ä»¶
`;

  const finalMessages = (outputTarget === "canvas")
    ? ([{ role: "system", content: CANVAS_SYSTEM_HINT }, ...messages])
    : messages;
  
  // å°†èŠå¤©æ¶ˆæ¯æ‹¼æˆçº¯æ–‡æœ¬è¾“å…¥ï¼ˆResponses æ¨èï¼‰
  const inputText = finalMessages
    .map(m => `${m.role}: ${m.content}`)
    .join("\n");

  const body = {
    model,
    input: inputText
  };

  // GPT-5 æ¨ç†å¼ºåº¦
  if (depthMode) {
    body.reasoning = { effort: "medium" };
  }

  // ğŸŒ OpenAI è”ç½‘æœç´¢ï¼ˆèƒ½åŠ› + options + env ä¸‰é‡åˆ¤æ–­ï¼‰
  if (
    webSearch === true &&
    process.env.OPENAI_WEB_SEARCH === "1"
  ) {
    body.tools = [{ type: "web_search" }];
  }


  const res = await fetchWithRetry(
    OPENAI_RESPONSES_URL,
    {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify(body)
    },
    { timeoutMs: 60000, retries: 2 }
  );

  const json = await res.json();
  if (!res.ok) {
    throw new Error(json.error?.message || "OpenAI Responses è°ƒç”¨å¤±è´¥");
  }

  return extractTextAndCanvas(json);
}

/** âœ… OpenAI Visionï¼ˆç»Ÿä¸€ Responses APIï¼‰ */
export async function callVisionOpenAI(buffer, mimeType) {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) throw new Error("ç¼ºå°‘ OPENAI_API_KEY");

  const base64 = buffer.toString("base64");

  const body = {
    model: "gpt-5-mini",
    input: [
      {
        role: "user",
        content: [
          { type: "input_text", text: "è¯·ç”¨ä¸­æ–‡è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹å’Œå…³é”®ä¿¡æ¯ã€‚" },
          {
            type: "input_image",
            image_base64: base64,
            mime_type: mimeType
          }
        ]
      }
    ]
  };

  const res = await fetchWithRetry(
    OPENAI_RESPONSES_URL,
    {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify(body)
    },
   { timeoutMs: 60000, retries: 2 }
  );

  const json = await res.json();
  if (!res.ok) {
    throw new Error(json.error?.message || "OpenAI Vision è°ƒç”¨å¤±è´¥");
  }

  return extractTextFromResponse(json);
}

/* ================= DeepSeek ================= */

async function callDeepSeek(model, messages, depthMode) {
  const apiKey = process.env.DEEPSEEK_API_KEY;
  if (!apiKey) throw new Error("ç¼ºå°‘ DEEPSEEK_API_KEY");

  const res = await fetchWithRetry(
    DEEPSEEK_BASE,
    {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model,
        messages,
        temperature: depthMode ? 0.2 : 0.7
      })
    },
    { timeoutMs: 60000, retries: 2 }
  );

  const json = await res.json();
  if (!res.ok) {
    throw new Error(json.error?.message || "DeepSeek è°ƒç”¨å¤±è´¥");
  }

  return json.choices?.[0]?.message?.content || "";
}

/* ================= Gemini ================= */

async function callGemini(model, messages, depthMode) {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) throw new Error("ç¼ºå°‘ GEMINI_API_KEY");

  const url = `${GEMINI_BASE}/models/${model}:generateContent?key=${apiKey}`;

  const contents = messages
    .filter(m => m.role !== "system")
    .map(m => ({
      role: m.role === "user" ? "user" : "model",
      parts: [{ text: m.content }]
    }));

  const res = await fetchWithRetry(
    url,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        contents,
        generationConfig: {
          temperature: depthMode ? 0.2 : 0.8
        }
      })
    },
    { timeoutMs: 60000, retries: 2 }
  );

  const json = await res.json();
  if (!res.ok) {
    throw new Error(json.error?.message || "Gemini è°ƒç”¨å¤±è´¥");
  }

  return json.candidates?.[0]?.content?.parts?.[0]?.text || "";
}

/* ================= ç»Ÿä¸€å‡ºå£ï¼ˆé˜²ç‚¸ï¼‰ ================= */

export async function callModel(provider, model, messages, depthMode) {
  try {
    if (provider === "openai") {
      return await callOpenAI(model, messages, depthMode);
    }
    if (provider === "deepseek") {
      return await callDeepSeek(model, messages, depthMode);
    }
    if (provider === "gemini") {
      return await callGemini(model, messages, depthMode);
    }
    throw new Error("æœªçŸ¥ provider: " + provider);
  } catch (err) {
    console.error(`[ModelError] ${provider}/${model}`, err);
    return "âš ï¸ å½“å‰æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•æˆ–åˆ‡æ¢æ¨¡å‹ã€‚";
  }
}
